{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711185422780318\n",
      "[[10103   993]\n",
      " [ 3239   318]]\n",
      "0.7408039309356446\n",
      "[[9132 1964]\n",
      " [1834 1723]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "# part 1\n",
    "ds=pd.read_csv('adult_data.csv')\n",
    "ds.income.replace(to_replace=['<=50K','<=50K.','>50K','>50K.'], value=[0,0,1,1],inplace=True)\n",
    "ds.drop(columns=['fnlwgt', 'education','capital-gain','capital-loss','native-country'],inplace=True)\n",
    "ds = ds.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "ds=pd.get_dummies(ds,['workClass','marital-status','occupation','relationship','race','sex'])\n",
    "targetCol=ds['income']\n",
    "ds.drop(columns=['income'],inplace=True)\n",
    "X_train, X_test, y_train, y_test=train_test_split(ds,targetCol,test_size=0.3,random_state=2)\n",
    "\n",
    "# part 2\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "results = confusion_matrix(y_test,y_pred) \n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(results)\n",
    "# part 3\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "results = confusion_matrix(y_test,y_pred)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-By looking in to the diagonal values of the confusion matrix and the accuracy score of both models we can conclude that the decision tree classifier is  performing better than the KNN.Moreover we observe that the accuracies of both models seem to be of low precision that is to say the predictions precison of  both the models are not very high as they should be.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
